{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb92755",
   "metadata": {},
   "source": [
    "# SINGLE NEURON\n",
    "\n",
    "Learn about linear units, the building blocks of deep learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d060dd2",
   "metadata": {},
   "source": [
    "## Welcome to Deep Learning!\n",
    "Welcome to Kaggle's Introduction to Deep Learning course! You're about to learn all you need to get started building your own deep neural networks. Using Keras and Tensorflow you'll learn how to:\n",
    "\n",
    "create a fully-connected neural network architecture\n",
    "\n",
    "apply neural nets to two classic ML problems: regression and classification\n",
    "\n",
    "train neural nets with stochastic gradient descent, and\n",
    "\n",
    "improve performance with dropout, batch normalization, and other techniques\n",
    "The tutorials will introduce you to these topics with fully-worked examples, and then in the exercises, you'll explore these topics in more depth and apply them to real-world datasets.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d18a5e",
   "metadata": {},
   "source": [
    "What is Deep Learning?\n",
    "Some of the most impressive advances in artificial intelligence in recent years have been in the field of deep learning. Natural language translation, image recognition, and game playing are all tasks where deep learning models have neared or even exceeded human-level performance.\n",
    "\n",
    "So what is deep learning? Deep learning is an approach to machine learning characterized by deep stacks of computations. This depth of computation is what has enabled deep learning models to disentangle the kinds of complex and hierarchical patterns found in the most challenging real-world datasets.\n",
    "\n",
    "Through their power and scalability neural networks have become the defining model of deep learning. Neural networks are composed of neurons, where each neuron individually performs only a simple computation. The power of a neural network comes instead from the complexity of the connections these neurons can form.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151988ef",
   "metadata": {},
   "source": [
    "## The Linear Unit\n",
    "So let's begin with the fundamental component of a neural network: the individual neuron. As a diagram, a neuron (or unit) with one input looks like:\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/mfOlDR6.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ada22f",
   "metadata": {},
   "source": [
    "The input is x. Its connection to the neuron has a weight which is w. Whenever a value flows through a connection, you multiply the value by the connection's weight. For the input x, what reaches the neuron is w * x. A neural network \"learns\" by modifying its weights.\n",
    "\n",
    "The b is a special kind of weight we call the bias. The bias doesn't have any input data associated with it; instead, we put a 1 in the diagram so that the value that reaches the neuron is just b (since 1 * b = b). The bias enables the neuron to modify the output independently of its inputs.\n",
    "\n",
    "The y is the value the neuron ultimately outputs. To get the output, the neuron sums up all the values it receives through its connections. This neuron's activation is y = w * x + b, or as a formula  y=wx+b\n",
    " .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239534c7",
   "metadata": {},
   "source": [
    "Example - The Linear Unit as a Model\n",
    "Though individual neurons will usually only function as part of a larger network, it's often useful to start with a single neuron model as a baseline. Single neuron models are linear models.\n",
    "\n",
    "Let's think about how this might work on a dataset like 80 Cereals( https://www.kaggle.com/crawford/80-cereals). Training a model with 'sugars' (grams of sugars per serving) as input and 'calories' (calories per serving) as output, we might find the bias is b=90 and the weight is w=2.5. We could estimate the calorie content of a cereal with 5 grams of sugar per serving like this: View the visual representation.\n",
    "\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/yjsfFvY.png\n",
    "And, checking against our formula, we have  calories=2.5×5+90=102.5\n",
    " , just like we expect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ea7b1",
   "metadata": {},
   "source": [
    "### Multiple Inputs\n",
    "The 80 Cereals dataset has many more features than just 'sugars'. What if we wanted to expand our model to include things like fiber or protein content? That's easy enough. We can just add more input connections to the neuron, one for each additional feature. To find the output, we would multiply each input to its connection weight and then add them all together. Follow this link to better visualize how it must be done.\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/vyXSnlZ.png\n",
    "\n",
    "The formula for this neuron would be  y=w0x0+w1x1+w2x2+b\n",
    " . A linear unit with two inputs will fit a plane, and a unit with more inputs than that will fit a hyperplane.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedd6ac",
   "metadata": {},
   "source": [
    "#### Linear Units in Keras\n",
    "The easiest way to create a model in Keras is through keras.Sequential, which creates a neural network as a stack of layers. We can create models like those above using a dense layer (which we'll learn more about in the next lesson).\n",
    "\n",
    "We could define a linear model accepting three input features ('sugars', 'fiber', and 'protein') and producing a single output ('calories') like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c250ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 16:54:52.687907: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-14 16:54:56.282701: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-14 16:54:56.289887: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-14 16:55:06.898327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#Create a network with 1 linear unit(neuron)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=1,input_shape=[3])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94693a13",
   "metadata": {},
   "source": [
    "With the first argument, units, we define how many outputs we want. In this case we are just predicting 'calories', so we'll use units=1.\n",
    "\n",
    "With the second argument, input_shape, we tell Keras the dimensions of the inputs. Setting input_shape=[3] ensures the model will accept three features as input ('sugars', 'fiber', and 'protein').\n",
    "\n",
    "This model is now ready to be fit to training data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c92a6",
   "metadata": {},
   "source": [
    "Why is input_shape a Python list?\n",
    "The data we'll use in this course will be tabular data, like in a Pandas dataframe. We'll have one input for each feature in the dataset. The features are arranged by column, so we'll always have input_shape=[num_columns]. The reason Keras uses a list here is to permit use of more complex datasets. Image data, for instance, might need three dimensions: [height, width, channels].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0351cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorrt\n",
      "  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: tensorrt\n",
      "  Building wheel for tensorrt (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[127 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/tensorrt\n",
      "  \u001b[31m   \u001b[0m copying tensorrt/__init__.py -> build/lib/tensorrt\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing tensorrt.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to tensorrt.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to tensorrt.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to tensorrt.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'tensorrt.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE.txt'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'tensorrt.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m /usr/lib/python3/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m installing to build/bdist.linux-x86_64/wheel\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m Looking in indexes: https://pypi.nvidia.com\n",
      "  \u001b[31m   \u001b[0m Collecting tensorrt_libs==8.6.1\n",
      "  \u001b[31m   \u001b[0m   Downloading https://pypi.nvidia.com/tensorrt-libs/tensorrt_libs-8.6.1-py2.py3-none-manylinux_2_17_x86_64.whl (824.8 MB)\n",
      "  \u001b[31m   \u001b[0m      ━                                      22.1/824.8 MB 164.8 kB/s eta 1:21:10\n",
      "  \u001b[31m   \u001b[0m ERROR: Exception:\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "  \u001b[31m   \u001b[0m     yield\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "  \u001b[31m   \u001b[0m     data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "  \u001b[31m   \u001b[0m     return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "  \u001b[31m   \u001b[0m     data = self.__fp.read(amt)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/http/client.py\", line 466, in read\n",
      "  \u001b[31m   \u001b[0m     s = self.fp.read(amt)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "  \u001b[31m   \u001b[0m     return self._sock.recv_into(b)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
      "  \u001b[31m   \u001b[0m     return self.read(nbytes, buffer)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
      "  \u001b[31m   \u001b[0m     return self._sslobj.read(len, buffer)\n",
      "  \u001b[31m   \u001b[0m TimeoutError: The read operation timed out\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m During handling of the above exception, another exception occurred:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "  \u001b[31m   \u001b[0m     status = run_func(*args)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 248, in wrapper\n",
      "  \u001b[31m   \u001b[0m     return func(self, options, args)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "  \u001b[31m   \u001b[0m     requirement_set = resolver.resolve(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
      "  \u001b[31m   \u001b[0m     result = self._result = resolver.resolve(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
      "  \u001b[31m   \u001b[0m     state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 397, in resolve\n",
      "  \u001b[31m   \u001b[0m     self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
      "  \u001b[31m   \u001b[0m     if not criterion.candidates:\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
      "  \u001b[31m   \u001b[0m     return bool(self._sequence)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "  \u001b[31m   \u001b[0m     return any(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "  \u001b[31m   \u001b[0m     return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "  \u001b[31m   \u001b[0m     candidate = func()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
      "  \u001b[31m   \u001b[0m     self._link_candidate_cache[link] = LinkCandidate(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n",
      "  \u001b[31m   \u001b[0m     super().__init__(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
      "  \u001b[31m   \u001b[0m     self.dist = self._prepare()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
      "  \u001b[31m   \u001b[0m     dist = self._prepare_distribution()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n",
      "  \u001b[31m   \u001b[0m     return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 538, in prepare_linked_requirement\n",
      "  \u001b[31m   \u001b[0m     return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 609, in _prepare_linked_requirement\n",
      "  \u001b[31m   \u001b[0m     local_file = unpack_url(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 166, in unpack_url\n",
      "  \u001b[31m   \u001b[0m     file = get_http_url(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 107, in get_http_url\n",
      "  \u001b[31m   \u001b[0m     from_path, content_type = download(link, temp_dir.path)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/network/download.py\", line 147, in __call__\n",
      "  \u001b[31m   \u001b[0m     for chunk in chunks:\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "  \u001b[31m   \u001b[0m     for chunk in iterable:\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "  \u001b[31m   \u001b[0m     for chunk in response.raw.stream(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "  \u001b[31m   \u001b[0m     data = self.read(amt=amt, decode_content=decode_content)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "  \u001b[31m   \u001b[0m     with self._error_catcher():\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "  \u001b[31m   \u001b[0m     self.gen.throw(typ, value, traceback)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "  \u001b[31m   \u001b[0m     raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "  \u001b[31m   \u001b[0m pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='pypi.nvidia.com', port=443): Read timed out.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-lcx81abp/tensorrt_c235dbedfdfd4bc29cb92b2409dbd539/setup.py\", line 49, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 153, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/distutils/core.py\", line 148, in setup\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/distutils/dist.py\", line 966, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/distutils/dist.py\", line 985, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3/dist-packages/wheel/bdist_wheel.py\", line 335, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command('install')\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/distutils/cmd.py\", line 313, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/distutils/dist.py\", line 985, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-lcx81abp/tensorrt_c235dbedfdfd4bc29cb92b2409dbd539/setup.py\", line 43, in run\n",
      "  \u001b[31m   \u001b[0m     install_dep(\"{:}_libs\".format(tensorrt_module))\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-lcx81abp/tensorrt_c235dbedfdfd4bc29cb92b2409dbd539/setup.py\", line 41, in install_dep\n",
      "  \u001b[31m   \u001b[0m     status.check_returncode()\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/lib/python3.10/subprocess.py\", line 457, in check_returncode\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(self.returncode, self.args, self.stdout,\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'install', 'tensorrt_libs==8.6.1', '--index-url', 'https://pypi.nvidia.com']' returned non-zero exit status 2.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for tensorrt\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for tensorrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build tensorrt\n",
      "\u001b[31mERROR: Could not build wheels for tensorrt, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bffb30",
   "metadata": {},
   "source": [
    "# MAKE YOUR MODELS DEEP\n",
    "\n",
    "## Introduction\n",
    "In this lesson we're going to see how we can build neural networks capable of learning the complex kinds of relationships deep neural nets are famous for.\n",
    "\n",
    "The key idea here is modularity, building up a complex network from simpler functional units. We've seen how a linear unit computes a linear function -- now we'll see how to combine and modify these single units to model more complex relationships.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174e69a",
   "metadata": {},
   "source": [
    "### LAYERS\n",
    "\n",
    "Neural networks typically organize their neurons into layers. When we collect together linear units having a common set of inputs we get a dense layer. View this image to grasp the visual representation described above:\n",
    "\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/2MA4iMV.png\n",
    "(Linear Networks with two inputs and a bias)\n",
    "\n",
    "You could think of each layer in a neural network as performing some kind of relatively simple transformation. Through a deep stack of layers, a neural network can transform its inputs in more and more complex ways. In a well-trained neural network, each layer is a transformation getting us a little bit closer to a solution.\n",
    "\n",
    "A \"layer\" in Keras is a very general kind of thing. A layer can be, essentially, any kind of data transformation. Many layers, like the convolutional and recurrent layers, transform data through use of neurons and differ primarily in the pattern of connections they form. Others though are used for feature engineering or just simple arithmetic. There's a whole world of layers to discover -- check them out!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493a01e",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "\n",
    "It turns out, however, that two dense layers with nothing in between are no better than a single dense layer by itself. Dense layers by themselves can never move us out of the world of lines and planes. What we need is something nonlinear. What we need are activation functions.\n",
    "\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/OLSUEYT.png\n",
    "\n",
    "######  Without activation functions, neural networks can only learn linear relationships. In order to fit curves, we'll need to use activation functions.\n",
    "\n",
    "An activation function is simply some function we apply to each of a layer's outputs (its activations). The most common is the rectifier function  max(0,x)\n",
    "Visually represented below:\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/aeIyAlF.png\n",
    "\n",
    "The rectifier function has a graph that's a line with the negative part \"rectified\" to zero. Applying the function to the outputs of a neuron will put a bend in the data, moving us away from simple lines.\n",
    "\n",
    "When we attach the rectifier to a linear unit, we get a rectified linear unit or ReLU. (For this reason, it's common to call the rectifier function the \"ReLU function\".) Applying a ReLU activation to a linear unit means the output becomes max(0, w * x + b), which we might draw in a diagram like:\n",
    "\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/eFry7Yu.png\n",
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6abe9e7",
   "metadata": {},
   "source": [
    "## STACKING DENSE LAYERS\n",
    "\n",
    "Now that we have some nonlinearity, let's see how we can stack layers to get complex data transformations.\n",
    "It is represented in the image below:\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/Y5iwFQZ.png\n",
    "(A stack of dense layers make a \"fully connected neural network)\n",
    "\n",
    "### Building Sequential Models\n",
    "\n",
    "The Sequential model we've been using will connect together a list of layers in order from first to last: the first layer gets the input, the last layer produces the output. This creates the model in the figure above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "621973c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    #hidden 'relu' layers\n",
    "    layers.Dense(units=4, activation='relu',input_shape=[2]),\n",
    "    layers.Dense(units=3, activation='relu'),\n",
    "    #linear unit\n",
    "    layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34296e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to write activation functions\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=32, input_shape=[8]),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(32),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318246f",
   "metadata": {},
   "source": [
    "# STOCHASTIC GRADIENT DESCENT\n",
    "\n",
    "#### Introduction¶\n",
    "In the first two lessons, we learned how to build fully-connected networks out of stacks of dense layers. When first created, all of the network's weights are set randomly -- the network doesn't \"know\" anything yet. In this lesson we're going to see how to train a neural network; we're going to see how neural networks learn.\n",
    "\n",
    "As with all machine learning tasks, we begin with a set of training data. Each example in the training data consists of some features (the inputs) together with an expected target (the output). Training the network means adjusting its weights in such a way that it can transform the features into the target. In the 80 Cereals dataset, for instance, we want a network that can take each cereal's 'sugar', 'fiber', and 'protein' content and produce a prediction for that cereal's 'calories'. If we can successfully train a network to do that, its weights must represent in some way the relationship between those features and that target as expressed in the training data.\n",
    "\n",
    "In addition to the training data, we need two more things:\n",
    "\n",
    "#### A \"loss function\" that measures how good the network's predictions are.\n",
    "##### An \"optimizer\" that can tell the network how to change its weights.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b6e52",
   "metadata": {},
   "source": [
    "#####  The Loss Function\n",
    "We've seen how to design an architecture for a network, but we haven't seen how to tell a network what problem to solve. This is the job of the loss function.\n",
    "\n",
    "The loss function measures the disparity between the the target's true value and the value the model predicts.\n",
    "\n",
    "Different problems call for different loss functions. We have been looking at regression problems, where the task is to predict some numerical value -- calories in 80 Cereals, rating in Red Wine Quality. Other regression tasks might be predicting the price of a house or the fuel efficiency of a car.\n",
    "\n",
    "A common loss function for regression problems is the mean absolute error or MAE. For each prediction y_pred, MAE measures the disparity from the true target y_true by an absolute difference abs(y_true - y_pred).\n",
    "\n",
    "The total MAE loss on a dataset is the mean of all these absolute differences.\n",
    "\n",
    "https://storage.googleapis.com/kaggle-media/learn/images/VDcvkZN.png\n",
    "The mean absolute error is the average length between the fitted curve and the data points.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40598526",
   "metadata": {},
   "source": [
    "Besides MAE, other loss functions you might see for regression problems are the mean-squared error (MSE) or the Huber loss (both available in Keras).\n",
    "\n",
    "During training, the model will use the loss function as a guide for finding the correct values of its weights (lower loss is better). In other words, the loss function tells the network its objective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16d94d",
   "metadata": {},
   "source": [
    "The Optimizer - Stochastic Gradient Descent\n",
    "We've described the problem we want the network to solve, but now we need to say how to solve it. This is the job of the optimizer. The optimizer is an algorithm that adjusts the weights to minimize the loss.\n",
    "\n",
    "Virtually all of the optimization algorithms used in deep learning belong to a family called stochastic gradient descent. They are iterative algorithms that train a network in steps. One step of training goes like this:\n",
    "\n",
    "Sample some training data and run it through the network to make predictions.\n",
    "\n",
    "Measure the loss between the predictions and the true values.\n",
    "\n",
    "Finally, adjust the weights in a direction that makes the loss smaller.\n",
    "\n",
    "Then just do this over and over until the loss is as small as you like (or until it won't decrease any further.)\n",
    "View a video of how the stochastic gradient descent works.\n",
    "\n",
    "(https://storage.googleapis.com/kaggle-media/learn/images/rFI1tIk.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccf5dd",
   "metadata": {},
   "source": [
    "Each iteration's sample of training data is called a minibatch (or often just \"batch\"), while a complete round of the training data is called an epoch. The number of epochs you train for is how many times the network will see each training example.\n",
    "\n",
    "The animation shows the linear model from Lesson 1 being trained with SGD. The pale red dots depict the entire training set, while the solid red dots are the minibatches. Every time SGD sees a new minibatch, it will shift the weights (w the slope and b the y-intercept) toward their correct values on that batch. Batch after batch, the line eventually converges to its best fit. You can see that the loss gets smaller as the weights get closer to their true values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd18b25",
   "metadata": {},
   "source": [
    "### Learning Rate and Batch Size\n",
    "Notice that the line only makes a small shift in the direction of each batch (instead of moving all the way). The size of these shifts is determined by the learning rate. A smaller learning rate means the network needs to see more minibatches before its weights converge to their best values.\n",
    "\n",
    "The learning rate and the size of the minibatches are the two parameters that have the largest effect on how the SGD training proceeds. Their interaction is often subtle and the right choice for these parameters isn't always obvious. (We'll explore these effects in the exercise.)\n",
    "\n",
    "Fortunately, for most work it won't be necessary to do an extensive hyperparameter search to get satisfactory results. Adam is an SGD algorithm that has an adaptive learning rate that makes it suitable for most problems without any parameter tuning (it is \"self tuning\", in a sense). ADAM is a great general-purpose optimizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964add75",
   "metadata": {},
   "source": [
    "#### Adding the Loss and Optimizer\n",
    "After defining a model, you can add a loss function and optimizer with the model's compile method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa961f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "optimizer='adam',loss=\"mae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf19f44",
   "metadata": {},
   "source": [
    "Notice that we are able to specify the loss and optimizer with just a string. You can also access these directly through the Keras API -- if you wanted to tune parameters, for instance -- but for us, the defaults will work fine.\n",
    "Notice that we are able to specify the loss and optimizer with just a string. You can also access these directly through the Keras API -- if you wanted to tune parameters, for instance -- but for us, the defaults will work fine.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2210301",
   "metadata": {},
   "source": [
    "#### What's In a Name?\n",
    "The gradient is a vector that tells us in what direction the weights need to go. More precisely, it tells us how to change the weights to make the loss change fastest. We call our process gradient descent because it uses the gradient to descend the loss curve towards a minimum. Stochastic means \"determined by chance.\" Our training is stochastic because the minibatches are random samples from the dataset. And that's why it's called SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b3ee1",
   "metadata": {},
   "source": [
    "### Example - Red Wine Quality\n",
    "Now we know everything we need to start training deep learning models. So let's see it in action! We'll use the Red Wine Quality dataset.\n",
    "\n",
    "This dataset consists of physiochemical measurements from about 1600 Portuguese red wines. Also included is a quality rating for each wine from blind taste-tests. How well can we predict a wine's perceived quality from these measurements?\n",
    "\n",
    "We've put all of the data preparation into this next hidden cell. It's not essential to what follows so feel free to skip it. One thing you might note for now though is that we've rescaled each feature to lie in the interval  [0,1]\n",
    " . As we'll discuss more in Lesson 5, neural networks tend to perform best when their inputs are on a common scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac5c4ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>10.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.171</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.063</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1109           10.8             0.470         0.43            2.10      0.171   \n",
       "1032            8.1             0.820         0.00            4.10      0.095   \n",
       "1002            9.1             0.290         0.33            2.05      0.063   \n",
       "487            10.2             0.645         0.36            1.80      0.053   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1109                 27.0                  66.0  0.99820  3.17       0.76   \n",
       "1032                  5.0                  14.0  0.99854  3.36       0.53   \n",
       "1002                 13.0                  27.0  0.99516  3.26       0.84   \n",
       "487                   5.0                  14.0  0.99820  3.17       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "1109     10.8        6  \n",
       "1032      9.6        5  \n",
       "1002     11.7        7  \n",
       "487      10.0        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "red_wine = pd.read_csv(\"./red-wine.csv\")\n",
    "\n",
    "#Create Training and validation \n",
    "df_train = red_wine.sample(frac=0.7,random_state=0)\n",
    "df_valid = red_wine.drop(df_train.index)\n",
    "\n",
    "display(df_train.head(4))\n",
    "\n",
    "#Scale to [0, 1]\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)\n",
    "\n",
    "# Split features and target\n",
    "X_train  = df_train.drop('quality', axis=1)\n",
    "X_valid = df_valid.drop('quality', axis=1)\n",
    "y_train = df_train['quality']\n",
    "y_valid = df_valid['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2421856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2ec23",
   "metadata": {},
   "source": [
    "How many inputs should this network have? We can discover this by looking at the number of columns in the data matrix. Be sure not to include the target ('quality') here -- only the input features.\n",
    "Eleven columns means eleven inputs.\n",
    "\n",
    "We've chosen a three-layer network with over 1500 neurons. This network should be capable of learning fairly complex relationships in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca960aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=[11]),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(512,activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e7372",
   "metadata": {},
   "source": [
    "Deciding the architecture of your model should be part of a process. Start simple and use the validation loss as your guide. You'll learn more about model development in the exercises.\n",
    "\n",
    "After defining the model, we compile in the optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579f99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "optimizer='adam',\n",
    "loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4828190",
   "metadata": {},
   "source": [
    "Now we're ready to start the training! We've told Keras to feed the optimizer 256 rows of the training data at a time (the batch_size) and to do that 10 times all the way through the dataset (the epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34557ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 20s 125ms/step - loss: 0.2766 - val_loss: 0.1346\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1422 - val_loss: 0.1220\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1236 - val_loss: 0.1181\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1167 - val_loss: 0.1082\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1110 - val_loss: 0.1091\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1075 - val_loss: 0.1034\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1047 - val_loss: 0.1062\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1034 - val_loss: 0.1022\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1026 - val_loss: 0.1008\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1007 - val_loss: 0.1019\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "X_train, y_train, validation_data=(X_valid,y_valid),\n",
    "batch_size=256,\n",
    "epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ae88d",
   "metadata": {},
   "source": [
    "You can see that Keras will keep you updated on the loss as the model trains.\n",
    "\n",
    "Often, a better way to view the loss though is to plot it. The fit method in fact keeps a record of the loss produced during training in a History object. We'll convert the data to a Pandas dataframe, which makes the plotting easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e473e1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert the training history to dataframe\n",
    "history_df = pd.DataFrame(history.history)\n",
    "# use pandas to native plot method\n",
    "history_df['loss'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3e4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
